{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5989f7f",
   "metadata": {},
   "source": [
    "## Modelle nutzen\n",
    "\n",
    "In der letzten Übung haben wir uns einen bestehenden Datensatz (Hauspreise) angeschaut und damit gearbeietet. Heute möchten wir dasselbe mit einem bestehenden Modell zu Erkennung von handschriftlichen Zahlen machen. MNIST ist ein bestehender Datensatz aus handschrifltichen Zahlen in Graustufen mit der Größe 28x28 Pixel. Auf Basis dieses Datensatzes wurde ein Modell trainiert und auf folgender Seite publiziert:\n",
    "\n",
    "https://www.kaggle.com/models/adhul000/mnist-99 \n",
    "\n",
    "Wie auch jeder Datensatz haben die meisten publizierten Modelle eine Model Card. Lesen Sie sich die Information auf der Seite zum Modell durch. \n",
    "\n",
    "Anhand der Model Card sehen wir, dass wir python 3.x benötigen (das bedeutet irgend ein Python in Version 3, egal ob 3.11, 3.12 oder höher). Weiterhin benötigen wir Tensorflow, eine Bibliothek zum Modell-Training und Modell ausführen (wird in Teil A näher behandelt). Kagglehub und Numpy sollten wir bereits in unserem venv installiert haben, wir können es aber zusätzlich in pip angeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf13d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install #todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f556d77a",
   "metadata": {},
   "source": [
    "Als nächstes laden wir uns das Modell von Kaggle herunter. Hierfür nutzen wir, wie bereits beim Datensatz, die Bibliothek kagglehub. Mit Angabe der Umbegungsvariablen ```KAGGLEHUB_CACHE``` können wir bestimmen wo unser Modell lokal auf der Festplatte gespeichert wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ee9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest model version\n",
    "os.environ['KAGGLEHUB_CACHE'] = 'data'\n",
    "#todo\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cecfd",
   "metadata": {},
   "source": [
    "Da wir nun ein fertig trainiertes Modell haben, können wir dies mit Tensorflow laden und verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(path, \"best_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dec992",
   "metadata": {},
   "source": [
    "Nun benötigen wir noch handschriftliche Zahlen, die wir erkennen können. Schreiben Sie hierfür eine Zahl auf einen Zettel und machen mit Ihrem Smartphone ein Bild davon. Das speichern Sie auf Ihrem Computer, am Besten in diesem Repository im Ordern ```imgs```. Schneiden Sie das Bild mit einem Bildverarbeitungsprogramm so zu, dass die Zahl möglichst das gesamte Bild ausfüllt. Sie finden zwei Beispiele im Ordner: ```3-6.JPG``` und ```3-8.JPG```.\n",
    "\n",
    "Wie in der Vorlesung behandelt ist nun die Herausforderung das Bild in das richtige Format und die richtige Pixelgröße zu bekommen. Hierfür erstellen wir uns eine Python-Funktion, welche einen Pfad zu einem Bild übergeben bekommt, das Bild lädt, transformiert und schließlich zurück gibt. Dafür setzen wir die Bibliothek PIL ein.\n",
    "\n",
    "Lesen Sie die Model Card aufmerksam: Welche Schritte müssen Sie ausführen, um Ihr fotografiertes Bild in das richtige Format für das Modell zu bringen? (*Anmerkung: die Schritte können auch eine andere Reihenfolge haben*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d46ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path: str) -> Image:\n",
    "    img = Image.open(image_path)  \n",
    "    # todo Schritt 1\n",
    "    # todo Schritt 2\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6848d5",
   "metadata": {},
   "source": [
    "Nun verwenden wir unsere Funktion, um das Bild in das richtige Format zu transformieren. Mit der Funktion ```show()``` können wir uns das Bild anzeigen lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_img = preprocess_image(os.path.join('imgs', '3-6.JPG'))\n",
    "\n",
    "preprocessed_img.show()\n",
    "print(\"Datentyp unseres Bildes: \", type(preprocessed_img))\n",
    "print(\"Array Größe des Bildes: \", preprocessed_img.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501760b",
   "metadata": {},
   "source": [
    "Nun wird es etwas tricky :). Folgende Schritte müssen wir noch durchführen, damit das Modell unser Bild akzeptiert: \n",
    "1) Bisher liegt unser Bild im Datentyp PI.Image.Image vor, das Modell möchte jedoch ein Numpy Array. Führen Sie einen Typecast mit ```np.array(..)``` durch. \n",
    "2) Weiterhin sind unsere Graustufen-Bilder im Wertebereich [0, 255], das mag unser Modell gar nicht, sondern möchte Werte im Bereich [0, 1]. Bringen Sie das Bild auf den entsprechenden Wertebereich (wir nennen dies Normalisieren).\n",
    "3) Das Bild liegt nun als 2-dimensionales Numpy Array (Breite x Höhe) vor. Das Modell erwartet jedoch ein Numpy Array des Shapes (X, 28, 28, 1), d.h. (AnzahlBilder, Breite, Höhe, AnzahlFarbChannels). In unserem Fall haben wir nur ein Bild zum Erkennen und als Grauwert nur einen Kanal, somit ist die neue Shape (1, 28, 28, 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e81432",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img = # todo Schritt 1\n",
    "np_img = # todo Schritt 2\n",
    "np_img = # todo Schritt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b7bb2",
   "metadata": {},
   "source": [
    "Das war's mit der Vorbereitung, nun lassen wir unser Modell mit ```predict(..)``` das Zeichen erkennen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1963182",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(np_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606756a4",
   "metadata": {},
   "source": [
    "Für jede Klasse Zahlen (0, 1, 2, .., 9) liefert unser Modell eine Erkennungswahrscheinlichkeit. Mit etwas Glück entspricht die Klasse mit der höchsten Wahrscheinlichkeit unserer Zahl. Ansonsten ist eventuell die Handschrift zu schlecht lesbar oder die Qualität des Bildes (vor allem Kontrast!) zu schlecht. Dann einfach erneut mit einem anderen Bild oder anderer Zahl probieren! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cda329",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = int(np.argmax(predictions[0]))\n",
    "print(f\"Das Modell erkennt die Zahl als: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29418e2b",
   "metadata": {},
   "source": [
    "Wenn Sie soweit gekommen sind probieren Sie gerne weitere Zahlen aus. Variieren Sie die Schreibweise (gut lesbar, schlecht lesbar) oder die Qualität des Bildes (hell, dunkel, guter Kontrast, schlechter Kontrast) und schauen was das Modell macht."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
